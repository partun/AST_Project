{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Create dataset for wrong assignment bugs\n",
    "\n",
    "Using the commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import codecs\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "benchmarks_dir = '../../../benchmarks'\n",
    "\n",
    "real_bugs_dataset_file_path = os.path.join(benchmarks_dir, 'assignments_real_bugs.pkl')\n",
    "real_bugs_dataset_dir = os.path.join(benchmarks_dir, 'assignments_real_bugs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_json_file(json_file_path) -> Dict:\n",
    "    try:\n",
    "        obj_text = codecs.open(json_file_path, 'r', encoding='utf-8').read()\n",
    "        return json.loads(obj_text)\n",
    "    except FileNotFoundError:\n",
    "        print(\n",
    "            \"Please provide a correct file p. Eg. ./results/validated-conflicts.json\")\n",
    "        return {}\n",
    "    except Exception as e:\n",
    "        # Empty JSON file most likely due to abrupt killing of the process while writing\n",
    "        # print (e)\n",
    "        return {}\n",
    "\n",
    "\n",
    "def read_dataset_given_files(extracted_data_files: List) -> pd.DataFrame:\n",
    "    d = []\n",
    "    with Pool(cpu_count()) as p:\n",
    "        with tqdm(total=len(extracted_data_files)) as pbar:\n",
    "            pbar.set_description_str(\n",
    "                desc=\"Reading dataset from files\", refresh=False)\n",
    "            for i, each_vars in enumerate(\n",
    "                    p.imap_unordered(read_json_file, extracted_data_files, 20)):\n",
    "                pbar.update()\n",
    "                d.extend(each_vars)\n",
    "            p.close()\n",
    "            p.join()\n",
    "    extracted_dataset = pd.DataFrame(d)\n",
    "    return extracted_dataset\n",
    "\n",
    "\n",
    "def file_path_to_dataset(dataset_file_path, dir_path):\n",
    "    if not Path(dataset_file_path).is_file():\n",
    "        file_paths = list(Path(dir_path).rglob('*.json'))\n",
    "        print(f\"Number of files={len(file_paths)}\")\n",
    "        dataset = read_dataset_given_files(extracted_data_files=file_paths)\n",
    "        print(f\"Saving {dataset_file_path}\")\n",
    "        dataset.to_pickle(dataset_file_path, 'gzip')\n",
    "    else:\n",
    "        print(f'Reading from {dataset_file_path}')\n",
    "        dataset = pd.read_pickle(dataset_file_path, 'gzip')\n",
    "    print(f\"Dataset contains {len(dataset)} examples\")\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_file_loc(row):\n",
    "    d = row.to_dict()\n",
    "    if 'benchmarks/real_bugs_github/buggy_' in d['src']:\n",
    "        file_name = d['src'].replace('benchmarks/real_bugs_github/buggy_', '')\n",
    "    else:\n",
    "        file_name = d['src'].replace('benchmarks/real_bugs_github/correct_', '')\n",
    "    range = str(d['range'][0])\n",
    "    return file_name + '_' + range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = file_path_to_dataset(dataset_file_path=real_bugs_dataset_file_path, dir_path=real_bugs_dataset_dir)\n",
    "row_iter = [row for _, row in dataset.iterrows()]\n",
    "locations = []\n",
    "for row in tqdm(row_iter):\n",
    "    loc = get_file_loc(row)\n",
    "    locations.append(loc)\n",
    "dataset['filename_loc'] = locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset['filename_loc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "correct_dataset = dataset[dataset['src'].apply(lambda x: 'correct_' in x)]\n",
    "buggy_dataset = dataset[dataset['src'].apply(lambda x: 'buggy_' in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "correct_dataset.iloc[0, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "buggy_dataset.iloc[0, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Length of correct dataset {len(correct_dataset)}')\n",
    "print(f'Length of buggy dataset {len(buggy_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "merged = correct_dataset.merge(buggy_dataset, left_on='filename_loc', right_on='filename_loc',\n",
    "                               suffixes=['_CORRECT', '_BUGGY'])\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_buggy_non_buggy_data(row):\n",
    "    d = row.to_dict()\n",
    "    correct = {k.replace('_CORRECT', ''): v for k, v in d.items() if '_CORRECT' in k}\n",
    "    correct['probability_that_incorrect'] = 0\n",
    "    buggy = {k.replace('_BUGGY', ''): v for k, v in d.items() if '_BUGGY' in k}\n",
    "    buggy['probability_that_incorrect'] = 1\n",
    "    if correct['lhs'] == buggy['lhs'] and correct['rhs'] != buggy['rhs']:\n",
    "        return [correct, buggy]\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "correct_assgn = []\n",
    "buggy_assgn = []\n",
    "x_y_pair_given = []\n",
    "for _, row in tqdm(list(merged.iterrows()), desc='Get lines'):\n",
    "    r = get_buggy_non_buggy_data(row)\n",
    "    if len(r):\n",
    "        correct_assgn.append(r[0])\n",
    "        buggy_assgn.append(r[1])\n",
    "        x_y_pair_given.append(r)\n",
    "print(f'Number of buggy/correct assignments extracted are {len(correct_assgn)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def write_json(content, out_file):\n",
    "    with open(out_file, 'w+') as f:\n",
    "        print(f'Writing to {f.name}')\n",
    "        json.dump(content, f)\n",
    "\n",
    "\n",
    "write_json(x_y_pair_given, os.path.join(benchmarks_dir, 'correct_buggy_real_wrong_assignments.json'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}